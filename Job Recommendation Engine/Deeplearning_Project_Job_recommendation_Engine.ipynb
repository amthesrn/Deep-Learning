{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DeepLearning Project**"
      ],
      "metadata": {
        "id": "ELcou0pmv77d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7seE1_L1vpF3",
        "outputId": "795e5731-16a5-4d6c-d3a9-09ab04bfe7fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Student_Latest_Data']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Student_Latest_Data']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Paths\n",
        "zip_file_path = \"/content/Student_Latest_Data.zip\"\n",
        "extract_to_path = \"/content/Student_Latest_Data\"\n",
        "\n",
        "# Unzip the file\n",
        "os.makedirs(extract_to_path, exist_ok=True)  # Ensure the extraction folder exists\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_path)\n",
        "\n",
        "# Verify extracted files\n",
        "extracted_files = os.listdir(extract_to_path)\n",
        "extracted_files\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "DQeQdIjUwq5U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the Excel file\n",
        "excel_file_path = \"/content/Student_Latest_Data/Student_Latest_Data/student_data.xlsx\"\n",
        "\n",
        "# Read the Excel file\n",
        "student_data = pd.read_excel(excel_file_path)\n",
        "\n",
        "# Display the first few rows of the data\n",
        "student_data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "5FrXk2ZVweU0",
        "outputId": "66084bec-83dd-4958-dcbd-7105358d12a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Roll No First Name Middle Name Last Name Degree 1  \\\n",
              "0  23070243001     Adrija         NaN      Paul    M.Sc.   \n",
              "1  23070243002     Anviya      Mariam     Bobby    M.Sc.   \n",
              "2  23070243004      Ayush         NaN     Dutta    M.Sc.   \n",
              "3  23070243005    Bhumika         NaN     Goyal    M.Sc.   \n",
              "4  23070243006     Chorge      Nikita    Dinesh    M.Sc.   \n",
              "\n",
              "  Degree 1 Primary Specializations  \\\n",
              "0                     Data Science   \n",
              "1                     Data Science   \n",
              "2                     Data Science   \n",
              "3                     Data Science   \n",
              "4                     Data Science   \n",
              "\n",
              "                                       Projects Name  \\\n",
              "0  Three Demographic Issues- Population Projectio...   \n",
              "1  Text Recognition Using Tesseract & Open CV; Pe...   \n",
              "2  Investment Risk Management; NLP for ESG Analys...   \n",
              "3  Salary Estimation using K-Nearest Neighbor; Fa...   \n",
              "4  Language detection and Translation; Customer s...   \n",
              "\n",
              "                                 Projects Key Skills  \\\n",
              "0  Tableau; LLM; Multiagent framework; R programm...   \n",
              "1  OpenCV; Natural Language Processing; Tesseract...   \n",
              "2  Unsupervised Learning; ML; Data Analysis; Opti...   \n",
              "3     Analysis; Python; analytical; Machine learning   \n",
              "4  Handling data imbalance; Feature engineering; ...   \n",
              "\n",
              "  Internship Experience - Organization Name (Industry - Stipend (In INR) - Start date to End date[Duration]) - Mentor Name (Designation - Phone - Email) - Academic Guide Name 1  \\\n",
              "0  Technocolabs Softwares (Banking / Financial Se...                                                                                                                               \n",
              "1  Prodigy Infotech (IT / Computers - Software - ...                                                                                                                               \n",
              "2  Indian Statistical Institute (NA - NA - 2024-0...                                                                                                                               \n",
              "3  Skysight.Ai (Technology - 5000 - 2024-03-16 to...                                                                                                                               \n",
              "4  Prodigy Infotech (NA - NA - 2024-02-01 to 2024...                                                                                                                               \n",
              "\n",
              "  Internship Experience - Organization Name (Industry - Stipend (In INR) - Start date to End date[Duration]) - Mentor Name (Designation - Phone - Email) - Academic Guide Name 2  \\\n",
              "0                                                NaN                                                                                                                               \n",
              "1                                                NaN                                                                                                                               \n",
              "2  Opsis System Pvt Ltd (Academics / Research - N...                                                                                                                               \n",
              "3  Mentorness (Technology - NA - 2024-02-01 to 20...                                                                                                                               \n",
              "4                                                NaN                                                                                                                               \n",
              "\n",
              "   ...           Co-Curricular Activities Extra Curricular Activities  \\\n",
              "0  ...                                NaN                         NaN   \n",
              "1  ...                                NaN                         NaN   \n",
              "2  ...                                NaN                         NaN   \n",
              "3  ...                                NaN                         NaN   \n",
              "4  ...  SIG's Decoration Committee Member                         NaN   \n",
              "\n",
              "  Seminar/Trainings/Workshops Title  Seminar/Trainings/Workshops Key Skills  \\\n",
              "0                               NaN                                     NaN   \n",
              "1                               NaN                                     NaN   \n",
              "2                               NaN                                     NaN   \n",
              "3                               NaN                                     NaN   \n",
              "4                               NaN                                     NaN   \n",
              "\n",
              "  Other Professional Experiences - Organization Name (Designation - Department - CTC (In INR) - Start date to End date[Duration]) 1  \\\n",
              "0                                                NaN                                                                                  \n",
              "1                                                NaN                                                                                  \n",
              "2                                                NaN                                                                                  \n",
              "3                                                NaN                                                                                  \n",
              "4                                                NaN                                                                                  \n",
              "\n",
              "  Other Professional Experiences - Organization Name (Designation - Department - CTC (In INR) - Start date to End date[Duration]) 2  \\\n",
              "0                                                NaN                                                                                  \n",
              "1                                                NaN                                                                                  \n",
              "2                                                NaN                                                                                  \n",
              "3                                                NaN                                                                                  \n",
              "4                                                NaN                                                                                  \n",
              "\n",
              "  Remaining Other Professional Experiences - Organization Name (Designation - Department - CTC (In INR) - Start date to End date[Duration])  \\\n",
              "0                                                NaN                                                                                          \n",
              "1                                                NaN                                                                                          \n",
              "2                                                NaN                                                                                          \n",
              "3                                                NaN                                                                                          \n",
              "4                                                NaN                                                                                          \n",
              "\n",
              "  Other Professional Experience - Industry  \\\n",
              "0                                      NaN   \n",
              "1                                      NaN   \n",
              "2                                      NaN   \n",
              "3                                      NaN   \n",
              "4                                      NaN   \n",
              "\n",
              "   Other Professional Experiences - Key Skills  \\\n",
              "0                                          NaN   \n",
              "1                                          NaN   \n",
              "2                                          NaN   \n",
              "3                                          NaN   \n",
              "4                                          NaN   \n",
              "\n",
              "   Assessments/Certification (Name - Aggregate Marks)  \n",
              "0  Google Business Intelligence Professional Cert...   \n",
              "1      IBM Big Data with Spark and Hadoop - 83.320;    \n",
              "2                                                NaN   \n",
              "3  Hacker Rank SQL(Basic) - NA; Chatgpt Explorati...   \n",
              "4  Introduction to Big Data with Spark and Hadoop...   \n",
              "\n",
              "[5 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c2520b0-6108-4131-ae8b-7aebdacb116a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Roll No</th>\n",
              "      <th>First Name</th>\n",
              "      <th>Middle Name</th>\n",
              "      <th>Last Name</th>\n",
              "      <th>Degree 1</th>\n",
              "      <th>Degree 1 Primary Specializations</th>\n",
              "      <th>Projects Name</th>\n",
              "      <th>Projects Key Skills</th>\n",
              "      <th>Internship Experience - Organization Name (Industry - Stipend (In INR) - Start date to End date[Duration]) - Mentor Name (Designation - Phone - Email) - Academic Guide Name 1</th>\n",
              "      <th>Internship Experience - Organization Name (Industry - Stipend (In INR) - Start date to End date[Duration]) - Mentor Name (Designation - Phone - Email) - Academic Guide Name 2</th>\n",
              "      <th>...</th>\n",
              "      <th>Co-Curricular Activities</th>\n",
              "      <th>Extra Curricular Activities</th>\n",
              "      <th>Seminar/Trainings/Workshops Title</th>\n",
              "      <th>Seminar/Trainings/Workshops Key Skills</th>\n",
              "      <th>Other Professional Experiences - Organization Name (Designation - Department - CTC (In INR) - Start date to End date[Duration]) 1</th>\n",
              "      <th>Other Professional Experiences - Organization Name (Designation - Department - CTC (In INR) - Start date to End date[Duration]) 2</th>\n",
              "      <th>Remaining Other Professional Experiences - Organization Name (Designation - Department - CTC (In INR) - Start date to End date[Duration])</th>\n",
              "      <th>Other Professional Experience - Industry</th>\n",
              "      <th>Other Professional Experiences - Key Skills</th>\n",
              "      <th>Assessments/Certification (Name - Aggregate Marks)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23070243001</td>\n",
              "      <td>Adrija</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Paul</td>\n",
              "      <td>M.Sc.</td>\n",
              "      <td>Data Science</td>\n",
              "      <td>Three Demographic Issues- Population Projectio...</td>\n",
              "      <td>Tableau; LLM; Multiagent framework; R programm...</td>\n",
              "      <td>Technocolabs Softwares (Banking / Financial Se...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Google Business Intelligence Professional Cert...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23070243002</td>\n",
              "      <td>Anviya</td>\n",
              "      <td>Mariam</td>\n",
              "      <td>Bobby</td>\n",
              "      <td>M.Sc.</td>\n",
              "      <td>Data Science</td>\n",
              "      <td>Text Recognition Using Tesseract &amp; Open CV; Pe...</td>\n",
              "      <td>OpenCV; Natural Language Processing; Tesseract...</td>\n",
              "      <td>Prodigy Infotech (IT / Computers - Software - ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IBM Big Data with Spark and Hadoop - 83.320;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23070243004</td>\n",
              "      <td>Ayush</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dutta</td>\n",
              "      <td>M.Sc.</td>\n",
              "      <td>Data Science</td>\n",
              "      <td>Investment Risk Management; NLP for ESG Analys...</td>\n",
              "      <td>Unsupervised Learning; ML; Data Analysis; Opti...</td>\n",
              "      <td>Indian Statistical Institute (NA - NA - 2024-0...</td>\n",
              "      <td>Opsis System Pvt Ltd (Academics / Research - N...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23070243005</td>\n",
              "      <td>Bhumika</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Goyal</td>\n",
              "      <td>M.Sc.</td>\n",
              "      <td>Data Science</td>\n",
              "      <td>Salary Estimation using K-Nearest Neighbor; Fa...</td>\n",
              "      <td>Analysis; Python; analytical; Machine learning</td>\n",
              "      <td>Skysight.Ai (Technology - 5000 - 2024-03-16 to...</td>\n",
              "      <td>Mentorness (Technology - NA - 2024-02-01 to 20...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hacker Rank SQL(Basic) - NA; Chatgpt Explorati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23070243006</td>\n",
              "      <td>Chorge</td>\n",
              "      <td>Nikita</td>\n",
              "      <td>Dinesh</td>\n",
              "      <td>M.Sc.</td>\n",
              "      <td>Data Science</td>\n",
              "      <td>Language detection and Translation; Customer s...</td>\n",
              "      <td>Handling data imbalance; Feature engineering; ...</td>\n",
              "      <td>Prodigy Infotech (NA - NA - 2024-02-01 to 2024...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>SIG's Decoration Committee Member</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Introduction to Big Data with Spark and Hadoop...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 37 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c2520b0-6108-4131-ae8b-7aebdacb116a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c2520b0-6108-4131-ae8b-7aebdacb116a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c2520b0-6108-4131-ae8b-7aebdacb116a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d3b43085-ed9a-4998-8327-d7053e107520\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d3b43085-ed9a-4998-8327-d7053e107520')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d3b43085-ed9a-4998-8327-d7053e107520 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "student_data"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the Excel file\n",
        "excel_file_path = \"/content/new_jobs_jd_300.csv\"\n",
        "\n",
        "# Read the Excel file\n",
        "job_data = pd.read_csv(excel_file_path)\n",
        "\n",
        "# Display the first few rows of the data\n",
        "job_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "31iyKvmzws9E",
        "outputId": "6f79da34-7e0c-4479-afbb-8254761e3110"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Job Title          Company  \\\n",
              "0    Data science interns  Zen Consultancy   \n",
              "1     Data Analyst Intern        FuelBuddy   \n",
              "2  Data Analytics Trainee     Ovid Metrics   \n",
              "3    Data science interns  Zen consultancy   \n",
              "4          Data Scientist    Web Secure AI   \n",
              "\n",
              "                                     Location  \\\n",
              "0        Mumbai, Maharashtra, India (On-site)   \n",
              "1           Gurgaon, Haryana, India (On-site)   \n",
              "2        Nashik, Maharashtra, India (On-site)   \n",
              "3  Bengaluru East, Karnataka, India (On-site)   \n",
              "4        Mumbai Metropolitan Region (On-site)   \n",
              "\n",
              "                                                Link  \\\n",
              "0  https://www.linkedin.com/jobs/view/4076706303/...   \n",
              "1  https://www.linkedin.com/jobs/view/4076700680/...   \n",
              "2  https://www.linkedin.com/jobs/view/4076555143/...   \n",
              "3  https://www.linkedin.com/jobs/view/4076709034/...   \n",
              "4  https://www.linkedin.com/jobs/view/4078149604/...   \n",
              "\n",
              "                                     Job_Description  \n",
              "0  Skills:\\nPython programming, Statistical analy...  \n",
              "1  Skills:\\nMicrosoft Power BI, Python, Advance E...  \n",
              "2  Skills:\\nPython, Tableau, SQL,\\n\\nKey Skills\\n...  \n",
              "3  Skills:\\nPython programming, Statistical analy...  \n",
              "4  Skills:\\nenglish, computer litracy, data scien...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a73d508-9dcd-44a3-a4dc-0197f9401ba5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Job Title</th>\n",
              "      <th>Company</th>\n",
              "      <th>Location</th>\n",
              "      <th>Link</th>\n",
              "      <th>Job_Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data science interns</td>\n",
              "      <td>Zen Consultancy</td>\n",
              "      <td>Mumbai, Maharashtra, India (On-site)</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/4076706303/...</td>\n",
              "      <td>Skills:\\nPython programming, Statistical analy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Analyst Intern</td>\n",
              "      <td>FuelBuddy</td>\n",
              "      <td>Gurgaon, Haryana, India (On-site)</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/4076700680/...</td>\n",
              "      <td>Skills:\\nMicrosoft Power BI, Python, Advance E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Analytics Trainee</td>\n",
              "      <td>Ovid Metrics</td>\n",
              "      <td>Nashik, Maharashtra, India (On-site)</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/4076555143/...</td>\n",
              "      <td>Skills:\\nPython, Tableau, SQL,\\n\\nKey Skills\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data science interns</td>\n",
              "      <td>Zen consultancy</td>\n",
              "      <td>Bengaluru East, Karnataka, India (On-site)</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/4076709034/...</td>\n",
              "      <td>Skills:\\nPython programming, Statistical analy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Web Secure AI</td>\n",
              "      <td>Mumbai Metropolitan Region (On-site)</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/4078149604/...</td>\n",
              "      <td>Skills:\\nenglish, computer litracy, data scien...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a73d508-9dcd-44a3-a4dc-0197f9401ba5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a73d508-9dcd-44a3-a4dc-0197f9401ba5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a73d508-9dcd-44a3-a4dc-0197f9401ba5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-49081a30-d563-4dec-83d3-681d2d312608\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-49081a30-d563-4dec-83d3-681d2d312608')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-49081a30-d563-4dec-83d3-681d2d312608 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "job_data",
              "summary": "{\n  \"name\": \"job_data\",\n  \"rows\": 180,\n  \"fields\": [\n    {\n      \"column\": \"Job Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 127,\n        \"samples\": [\n          \"Fraud Strategy Analyst 1\",\n          \"Product Analyst - Transactions\",\n          \"Artificial Intelligence Engineer - Computer Vision\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Company\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 112,\n        \"samples\": [\n          \"Signant Health\",\n          \"Barclays\",\n          \"Web Secure AI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"Mumbai, Maharashtra, India (On-site)\",\n          \"Chennai, Tamil Nadu, India (On-site)\",\n          \"Bengaluru South, Karnataka, India (On-site)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 180,\n        \"samples\": [\n          \"https://www.linkedin.com/jobs/view/4076830404/?eBP=CwEAAAGTRaEl0SU_iuR5wUYrP2T1VjYPHuj3sa_hgI_WDpZEe1aFlpe4Z98HzCSsDFsfD_SkRRpJDuVEq-dYIOMS6d9d-qo2I9xOCQp-mRSsYcRI3fHWFYb546AUzOqi5g733RUGKyLrvJeF3mQ1bH90B9clqDAK8TVxVC_v4qiFTSKYfupBqNKylNwhKLHTYnCuzex98ySL-zWguvBUhqPPF7nqNJ7JBY4PBCTQNUJkH7jRCrUL0tRCYSa67I9JTo8r8A7L7KeAT6ud9RjC6B38byfzbDnavIgCrD8GYWGp-5KXhy2uFzGhRKgX7VVcYmUOFEg2I-E7RaaRSyvVNaNICr7EhJJXxlrOh8hnoE-3FUmE_q17rzKVJuSOw88aplIUvprlo8-uyiAZQUKHBbZWNYvltKyWLSXhZ58gch_hUyvvXwmK7mt8u9lQmCcYg_gLL_EqAI_0v9wSfT4&refId=NSxkCJkcFzIOaawklT58Dw%3D%3D&trackingId=E9dpCGFq%2FVgR7cNVn%2BvQIQ%3D%3D&trk=flagship3_search_srp_jobs\",\n          \"https://www.linkedin.com/jobs/view/4077868074/?eBP=CwEAAAGTRaHGdEObMlOHOsdUrddU9MEUq_0ZdjcWR2hrSFYq1cdwrFS7iul2ma7YYr91wBLWndDr7wfBGlnQ7JNZrZRZvFwr-ttXd-ZjYG85KxyyEYNxXAyG2iT6c9u_iqom6UTkaDmNjuF4PX8Vxz7oGe6TFQMx-bFxsXfxoOdRTxh8a6UCjqV3YsyEdxophgwRWfJCRm1NzoLf1opv04YbhT5R-sWREBmmZ3WfeSzn9ZR-cp_Eb24s_uGPCgOrWOU1BxUJ3ljTL8w-PUvdav_Txi6h__mcbkW4De33rU9SPxvG2PGYbPif1lciUpW26Bn1PeCWYs7P6lQg9b4WmGYl-GFYKiZf60u_bjTjK-Gr1kp2xz6ne_ZebSUGgGEErJMaXUAksp9ZSzAwP_22J-XC1DIhHO2ATR3K-gT5ea5ws1FPxDZFRIWL780xeBsiqcuKJvieUuG4FVdCIb8EYGWb6zFddAPaeUEcKKv3SfvMnxkRP1eLxmnkAqqAQz5ll_gYHoOhj16Xo7ZLCT89OJZG7sZ_p0Y&refId=3azH6MS4jVtUXR%2BP5fZ01w%3D%3D&trackingId=xntZJ4EMAulSqzY6K5buxw%3D%3D&trk=flagship3_search_srp_jobs\",\n          \"https://www.linkedin.com/jobs/view/4075283663/?eBP=CwEAAAGTRaLPeht5UdPeCgIZLV7nJ50ZGaFlzg6-OQ_NOJXv0pJzGXSHR1j09VlYfC-DU5uH1kKmNzl-EgL_6q3hy4nvAsKRgsVyBLgVT3yEIzwkQDkk6rR7ZV1LqaxmuPlZXAPaqDQARGkfw-VDTDY2pQiouubyixDmxvv62V-ZDFWFs9FFzu0XmEcHHx87V2jgbKBkQiChbF4go3aCG8q9EsN3rd4kQJ0J3IK7Bq8AwfxGHOKNWUngTUg_wGpnQUYbkvUuILKLsP_C7WttFDD_8hQm-B5_fqbTYy3EVt9ddOOFuT80AxoBu_-PGBBe-30GxtSF3BBKY8w9CCAnzkTdgE2NpmXtO1ZzlI3taLKTozbegtzxXiR05spv7bn9PdBWhai84gIctt1-8BEWaJLNVH8O3y9RdKBOEKBds1CRqSMPdep5HIsyn_h3t_9unTrlJ8ZxIjYvE091OmAo7M0DbLLG_lqaZkSO2XlF3AmIo1Ri&refId=f3z%2BIaEWJNxHIUc76BESCQ%3D%3D&trackingId=EvmtKAIclGKUwe1BAAtAxw%3D%3D&trk=flagship3_search_srp_jobs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Job_Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 151,\n        \"samples\": [\n          \"Join our Noida team as a business analyst and be responsible for monthly forecasting, annual budgeting, and financial modeling. You will also prepare and publish monthly reports, interpret data, and use statistical techniques to analyze results.\\n\\nKey Responsibilities\\n\\n Assist with modeling scenario-based business plans, annual budgeting, and monthly forecasting processes\\n Perform financial analysis and financial modeling\\n Help prepare and publish monthly reports and analytics for the business\\n Interpret data, analyze results using statistical techniques, and provide ongoing reports\\n Develop and implement databases, data collection systems, data analytics of business process, and other strategies that optimize statistical efficiency and quality\\n Identify, analyze, and interpret trends or patterns in financial data sets\\n Work with management to prioritize business and information needs\\n Develop and track cross-company efforts to improve gross margin and cash flow\\n\\nAbout Company: At MH London, we represent everything stylish & modern yet simple and refined. We are a young company based in the UK, US, India, and soon, across the globe. Our passion for creating world-class products with a touch of modern design and affordability is what unites our amazing team of innovators and thinkers. For us, aesthetics, utility & simplicity are at the core of everything. We pride ourselves in our attention to detail to create designer & modern products making your home a better place to live happily & better every day. Most of our products are handcrafted, so there is a story behind every product we sell.\",\n          \"Skills:\\nEnglish, computer litracy, data science, data, Data Analysis, Statistical Data Analysis,\\n\\nAbout The Job\\n\\nSolar Secure Solutions is a Web Development & Designing company with its headquarter in New Delhi India and started it's operation in 2018. We provide a variety of tools to the businesses to grow and increase their productivity like Web Designing, SEO, Digital Marketing and promotion, Logo Design, Content writing etc. We are a fast growing company so opportunities are more.\\n\\nCurrently offering \\\"Data Science Internship\\\" for 2 months.\\n\\nData Science Projects details In which Interns Will Work :\\n\\nProject 01 : Image Caption Generator Project in Python\\n\\nProject 02 : Credit Card Fraud Detection Project\\n\\nProject 03 : Movie Recommendation System\\n\\nProject 04 : Customer Segmentation\\n\\nProject 05 : Brain Tumor Detection with Data Science\\n\\nEligibility\\n\\nA PC or Laptop with decent internet speed.\\n\\nGood understanding of English language.\\n\\nAny Graduate with a desire to become a web developer. Freshers are welcomed.\\n\\nKnowledge of HTML, CSS and JavaScript is a plus but NOT mandatory.\\n\\nFresher are welcomed. You will get proper training also, so don't hesitate to apply if you don't have any coding background.\\n\\nDuration : 02 Months \\n\\nMODE: Work From Home (Online)\\n\\nResponsibilities\\n\\nManage reports and sales leads in salesforce.com, CRM.\\n\\nDevelop content, manage design, and user access to SharePoint sites for customers and employees.\\n\\nBuild data driven reports, store procedures, query optimization using SQL and PL/SQL knowledge.\\n\\nLearned the essentials to C++ and Java to refine code and build the exterior layer of web pages.\\n\\nConfigure and load xml data for the BVT tests.\\n\\nSet up a GitHub page.\\n\\nDevelop spark scripts by using Scala shell as per requirements.\\n\\nDevelop and A/B test improvements to business survey questions on iOS.\\n\\nDeploy statistical models to various company data streams using Linux shells.\\n\\nCreate monthly performance-base client billing reports using MySQL and NoSQL databases.\\n\\nUtilize Hadoop and MapReduce to generate dynamic queries and extract data from HDFS.\\n\\nCreate source code utilizing JavaScript and PHP language to make web pages functional.\\n\\nBenefits\\n\\nInternship Certificate\\n\\nLetter of recommendation\\n\\nStipend Performance Based\\n\\nPart time work from home (2-3 Hrs per day)\\n\\n5 days a week, Fully Flexible Shift\",\n          \"Position TitleD&T Analyst I \\u2013 Business Intelligence\\n\\nFunction/Group\\n\\nDigital and Technology\\n\\nLocation\\n\\nMumbai\\n\\nShift Timing\\n\\n11 AM \\u2013 8 PM\\n\\nRole Reports to\\n\\nManager\\n\\nRemote/Hybrid/in-Office\\n\\nHybrid\\n\\nAbout General Mills\\n\\nWe make food the world loves: 100 brands. In 100 countries. Across six continents. With iconic brands like Cheerios, Pillsbury, Betty Crocker, Nature Valley, and H\\u00e4agen-Dazs, we\\u2019ve been serving up food the world loves for 155 years (and counting). Each of our brands has a unique story to tell.\\n\\nHow we make our food is as important as the food we make. Our values are baked into our legacy and continue to accelerate\\n\\nus into the future as an innovative force for good. General Mills was founded in 1866 when Cadwallader Washburn boldly bought the largest flour mill west of the Mississippi. That pioneering spirit lives on today through our leadership team who upholds a vision of relentless innovation while being a force for good. For more details check out http://www.generalmills.com\\n\\nGeneral Mills India Center (GIC) is our global capability center in Mumbai that works as an extension of our global organization delivering business value, service excellence and growth, while standing for good for our planet and people.\\n\\nWith our team of 1800+ professionals, we deliver superior value across the areas of Supply chain (SC) , Digital & Technology (D&T) Innovation, Technology & Quality (ITQ), Consumer and Market Intelligence (CMI), Sales Strategy & Intelligence (SSI) , Global Shared Services (GSS) , Finance Shared Services (FSS) and Human Resources Shared Services (HRSS).For more details check out https://www.generalmills.co.in\\n\\nWe advocate for advancing equity and inclusion to create more equitable workplaces and a better tomorrow.\\n\\nJob Overview\\n\\nFunction Overview\\n\\nThe Digital and Technology team at General Mills stands as the largest and foremost unit, dedicated to exploring the latest trends and innovations in technology while leading the adoption of cutting-edge technologies across the organization. Collaborating closely with global business teams, the focus is on understanding business models and identifying opportunities to leverage technology for increased efficiency and disruption. The team's expertise spans a wide range of areas, including AI/ML, Data Science, IoT, NLP, Cloud, Infrastructure, RPA and Automation, Digital Transformation, Cyber Security, Blockchain, SAP S4 HANA and Enterprise Architecture. The MillsWorks initiative embodies an agile@scale delivery model, where business and technology teams operate cohesively in pods with a unified mission to deliver value for the company. Employees working on significant technology projects are recognized as Digital Transformation change agents.\\n\\nThe team places a strong emphasis on service partnerships and employee engagement with a commitment to advancing equity and supporting communities. In fostering an inclusive culture, the team values individuals passionate about learning and growing with technology, exemplified by the \\\"Work with Heart\\\" philosophy, emphasizing results over facetime. Those intrigued by the prospect of contributing to the digital transformation journey of a Fortune 500 company are encouraged to explore more details about the function through the provided Link\\n\\nPurpose of the role\\n\\nThe Digital and Technology team of General Mills India Centre is looking for a passionate and enthusiastic individual to contribute as a D&T Analyst I \\u2013 Business Intelligence. This role will report into D&T Manager, DIV in India and functionally collaborate with the various verticals of General Mills.\\n\\nThe Data Insights & Visualization team caters to various reporting, visualization & insights initiatives to support and aid in decision making for various Operating Units and Business functions. The team operates in Agile manner and works in partnership with product teams to deliver turnkey BI solutions.\\n\\nThis individual contributor role of D&T Analyst I \\u2013 Business Intelligence, would be working with the business & technical team and would be responsible to build/standardize/enhance BI solutions. The person will collaborate and partner with various D&T teams to collectively deliver on the problem statement through optimum, standardized & user-friendly solution.\\n\\nKey Accountabilities\\n\\nProduct Design, Development & Analytics:\\n\\nDesign, develop, Maintain, and launch new Business Intelligence visualization & reporting solutions leveraging Tableau, Looker, DOMO, Advance Excel, etc.\\nImplement\\u202fenterprise\\u202fBusiness Intelligence standards, best practices and approved BI techniques.\\nWork alongside of peers and inculcate best practices (data prep tools, connected data approaches, data cataloguing etc. which can elevate the team\\u2019s ability to tackle business and technical challenges\\nDevelop, Maintain, and implement standard processes, tools/solutions to ensure best practices are followed in the deliverables.\\nCollaborate with stakeholders to understand requirements and work alongside peers to identify best approach for data validation, metric definition & Insight representation.\\nAbility to research and find technical solutions via technical community collaboration.\\nFollow Agile approach with various work streams during design, development, and signoffs from stakeholders to roll out reimagined reporting solutions across the org.\\nDevelop technical architectures and prototypes for dashboards, through coordination with product teams.\\nActively participate in various phases of the project including defining the core requirement, effort estimation, root-cause analysis, solutioning, development and deployment \\nApply thought leadership to deliver application of insights through absorbed domain/functional business acumen.\\nPartner with technical teams to troubleshoot technical and performance issues in the big data ecosystem.\\nPerform in-depth analysis to identify key business data elements & metrics to enable insights.\\n\\nStrategy & Collaboration\\n\\nTranslate business challenges into impactful dashboard designs and technical builds.\\nPartner along with product team with business stakeholders to understand project requirements and lead BI engagement, execution & delivery.\\nDetail-oriented, a strong communicator, incredibly curious, and technically capable with a desire to discover and deliver data-driven business insights to fuel our data-driven culture and help us make informed business decisions.\\nCollaborate with teams across functions to set internal benchmarks, develop critical metrics for new initiatives, and recommend best practices.\\nCoordinate triage efforts, resolve user issues and system improvements.\\n\\nMinimum Qualifications\\n\\nBachelor\\u2019s degree from accredited university (Full Time) in Business Analytics or a related subject area\\n4+ years of total experience with 3+ years of relevant experience working with business stakeholders and designing analytical solutions.\\nExtensive experience in creating interactive dashboards using Tableau (Intermediate) and other visualization tools (Basic) \\u2013 Domo, Looker, Business Objects, Advance Excel, SQL, etc.\\nGood communication skills, capable of translating business requests into technical requirements and articulating the pros and cons of different technologies, platforms, design and architectural options.\\nBasic understanding of data and analytics tools and concepts, including ETL, reporting tools, data governance, data warehousing.\\nBasic understanding of data extraction using Google Big Query, SQL Server, SAP BW or SAP HANA\\n\\nPreferred Qualifications\\n\\nThought-driven leadership to successfully deliver scalable team management and business solutions.\\nKnowledge of at least one other programming language such as Python is a plus.\\nTakes the initiative to do the right thing - doesn't walk past a problem.\\nConsultant mindset - able to challenge with courage and influence upwards and with peers.\\nAgile learner - has passion and curiosity to learn new things and understand the \\\"why\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLjk_8dQzR9E",
        "outputId": "16744f3a-2e6b-4880-e8cb-22e5b59fa6c1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import PyPDF2\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Set up spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")  # Download spaCy English model\n",
        "\n",
        "# Paths\n",
        "excel_path = \"/content/Student_Latest_Data/Student_Latest_Data/student_data.xlsx\"\n",
        "resume_folder = \"/content/Student_Latest_Data/Student_Latest_Data/New_resume\"\n",
        "job_csv_path = \"/content/new_jobs_jd_300.csv\"\n",
        "\n",
        "# Load the job data\n",
        "job_data = pd.read_csv(job_csv_path)\n",
        "\n",
        "# Ensure required columns are present\n",
        "required_columns = ['Job Title', 'Company', 'Location', 'Link', 'Job_Description']\n",
        "if not all(col in job_data.columns for col in required_columns):\n",
        "    raise ValueError(\"Job data CSV file is missing required columns.\")\n",
        "\n",
        "# Function to preprocess text using spaCy (removes stop words and punctuation)\n",
        "def preprocess_text(text):\n",
        "    doc = nlp(text.lower())  # Process the text using spaCy\n",
        "    filtered_words = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "# Function to extract text from a PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "            return text\n",
        "    except Exception as e:\n",
        "        return f\"Error reading PDF: {e}\"\n",
        "\n",
        "# Function to recommend jobs\n",
        "def recommend_jobs(resume_text, job_data, top_n=5):\n",
        "    # Preprocess job descriptions\n",
        "    job_data['Processed_Job_Description'] = job_data['Job_Description'].fillna(\"\").apply(preprocess_text)\n",
        "\n",
        "    # Encode job descriptions and resume using Sentence-BERT\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    job_embeddings = model.encode(job_data['Processed_Job_Description'].tolist(), convert_to_tensor=True)\n",
        "    resume_embedding = model.encode(preprocess_text(resume_text), convert_to_tensor=True)\n",
        "\n",
        "    # Move tensors to CPU and convert to NumPy arrays\n",
        "    job_embeddings = job_embeddings.cpu().numpy()\n",
        "    resume_embedding = resume_embedding.cpu().numpy()\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    similarity_scores = cosine_similarity([resume_embedding], job_embeddings).flatten()\n",
        "    job_data['similarity_score'] = similarity_scores\n",
        "\n",
        "    # Get top job recommendations\n",
        "    top_jobs = job_data.nlargest(top_n, 'similarity_score')[['Job Title', 'Company', 'Location', 'Link', 'similarity_score']]\n",
        "    return top_jobs\n",
        "\n",
        "# Main function for user input\n",
        "def main():\n",
        "    # User input\n",
        "    roll_no = input(\"Enter the Roll Number: \").strip()\n",
        "    resume_path = os.path.join(resume_folder, f\"{roll_no}.pdf\")\n",
        "\n",
        "    if not os.path.exists(resume_path):\n",
        "        print(f\"Resume not found for Roll No: {roll_no}\")\n",
        "        return\n",
        "\n",
        "    # Extract text from the resume\n",
        "    resume_text = extract_text_from_pdf(resume_path)\n",
        "    if resume_text.startswith(\"Error\"):\n",
        "        print(f\"Error reading resume for Roll No: {roll_no}\")\n",
        "        return\n",
        "\n",
        "    # Recommend jobs\n",
        "    top_jobs = recommend_jobs(resume_text, job_data)\n",
        "\n",
        "    # Display top 5 jobs\n",
        "    print(f\"\\nTop 5 Job Recommendations for Roll No: {roll_no}\")\n",
        "    for idx, job in enumerate(top_jobs.to_dict(orient='records'), start=1):\n",
        "        print(f\"\\nJob {idx}:\")\n",
        "        print(f\"  - Title: {job['Job Title']}\")\n",
        "        print(f\"  - Company: {job['Company']}\")\n",
        "        print(f\"  - Location: {job['Location']}\")\n",
        "        print(f\"  - Similarity Score: {job['similarity_score']:.2f}\")\n",
        "        print(f\"  - [Apply Here]({job['Link']})\")\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6VCAp5YxpAI",
        "outputId": "35450ebc-b118-4de4-c39f-9539a39226d3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the Roll Number: 23070243065\n",
            "\n",
            "Top 5 Job Recommendations for Roll No: 23070243065\n",
            "\n",
            "Job 1:\n",
            "  - Title: Data Science\n",
            "  - Company: NextGen AI solutions\n",
            "  - Location: Hyderabad, Telangana, India (On-site)\n",
            "  - Similarity Score: 0.84\n",
            "  - [Apply Here](https://www.linkedin.com/jobs/view/4076708831/?eBP=CwEAAAGTRaHGdIfOi4YnNHs_SCX8qerjjy522hazv2ytHwY-1pQYkq6ysmVBIgpyJsDB6mBPODC_4qUPE59rFwqNr1l1zgOJNNNnq7saoAFPWdeAYez01lHK5XRJu2quQe-SWQpgQUqcMxBpmyYSXZ3ynUq2jKtBvI8CPA9DYoS29FZViQUhgT2PSxPcqQaBcl8sl7x1d76AXPnL5BJTvg19Dsu3DK69D8YGEh-fX7grgmBQWm-6jpOkmUNznk048lvMctoU_AHNor7wXGYY3DxeR5iXEt7OPEPpphkQvVecb_etTRrnDghWq7RzAFivu7WVLrLPTd_5gns-NiAiYR5Gqdq4DizxgTSkqVBuuDQl1hLka0lRnqj8xo93EEPfPmx9t40ShubskUrYLJbokD-I7Hhfy7qwfeYRLsVCd2p25H-xmaH1Bwlo5rGLNJxIkcDbIxJH5YSt63S_YwCDCba6AeGujQhedPZpoYam5ooT4cimj96XY5VIzAHz-D-Fx0Y&refId=3azH6MS4jVtUXR%2BP5fZ01w%3D%3D&trackingId=JUWtsH%2BPE4WYXo3MOvvUaQ%3D%3D&trk=flagship3_search_srp_jobs)\n",
            "\n",
            "Job 2:\n",
            "  - Title: Data Scientist\n",
            "  - Company: Web Secure AI\n",
            "  - Location: Mumbai Metropolitan Region (On-site)\n",
            "  - Similarity Score: 0.84\n",
            "  - [Apply Here](https://www.linkedin.com/jobs/view/4078149604/?eBP=CwEAAAGTRaEKIy13fDqnoCSLXcD4_ETWlYfl8Wet3vlPe-iJFTWm91nNgOd4Qvde8NzesNVcZmyBeDHEsDGYzyPP7KdIN-cX0If6dwZaq9BqN9XcqjjIGiDogsSItpVXokOTMUXFEaEe7WkxtWmwej5on8O2IWk8jxiDiFHz9ELEeyxUkY5ggWwW_gLR6dzwS-8dOWJtv32PzqfZvC9nkFXfT1iyD-GMsYyc_3-G6uS_8DuhyN96OiqnTbcFGYK4_DSFSGzM9vIFp__RPC35xMI-IggPyXJXJjn9sPL0A8PZOMbn_fjJXwFf4ayifd4qpb5x36FZsx-hFIehCIUDCIOJNoManQB-djzooUOE3Z7-wsLCZ8o3q4wnclJ7js_2qqmbeWgKM10UsFK6wkfg5DZ459aWu4o4jMjUGQmCHi9lB4K-8QEPdt_WDAZ4ZFww3KsdZPJf0HSi2knDE2V6DbQCkey5fd7rsdr0JKyN1-ZGMrutUnb0p4inXqPV_o6PCNg&refId=QGoCTs2m3FDfMmPU5MDxsg%3D%3D&trackingId=cmTymxXkPfJHRedf9aBe7A%3D%3D&trk=flagship3_search_srp_jobs)\n",
            "\n",
            "Job 3:\n",
            "  - Title: Data Science Intern\n",
            "  - Company: Solar Secure Solutions\n",
            "  - Location: Hyderabad, Telangana, India (On-site)\n",
            "  - Similarity Score: 0.81\n",
            "  - [Apply Here](https://www.linkedin.com/jobs/view/4076581970/?eBP=CwEAAAGTRaGMHznzeb_tJUyggsbrTS_GC7VxFNvZSQeFnjNouepOA-lZz0QddbyetezNVfb3SReJoAnshsQFugMuX_eZF3mHIKvRJB-9JRnKYhLDqBp-gIcMipm3Q5tBo8GBpu7E83qL8htMDOJhvxYeYmO1pRReiHn3JiGhzrdbhrXxrPzqXaTXB9u93B8Qe70ygySojwzm9Xgg6RJ3dKSMWcWaHwTUIOGJNQNwTCTqOc_ratO1EDCzKSXbuHZuzVpxhwlvTaw6Gc5S2BQH9n4T8jeTyyYBxjUExV-L6NLngGVtri4umqm0qTrbAPydTkKQoQ5DMVLtZa97BGrNEw1AEGLyHfr6JdDcPyHCMZAB7HFxpfSb4SG40Dp_zSXerkHST-rfhwkgEZzTummKxZ_chioA7PCIQz_3Jv_GwwMv9Xmza0lWGZ0NW0oQPzKsiWd_W7c0RVUSC1t069xdUnDQHX_vnq5tuZN8fA5opJIJKq8hURv1cysmoUqsis5RBi9T9d-O&refId=xQf68Oz%2BTrKf1ww6eeD%2BIA%3D%3D&trackingId=OpLvLvB7qfBcDM7lqQgcrQ%3D%3D&trk=flagship3_search_srp_jobs)\n",
            "\n",
            "Job 4:\n",
            "  - Title: Data Scientist\n",
            "  - Company: Web Secure AI\n",
            "  - Location: Bengaluru, Karnataka, India (On-site)\n",
            "  - Similarity Score: 0.79\n",
            "  - [Apply Here](https://www.linkedin.com/jobs/view/4076720819/?eBP=CwEAAAGTRaEKJKIAvtTFSw9bpnzWnEFZ-ebpdZhAKSixshKdv5DGaibNIdQtGPE6XWsWejm0K06JPJSNt72KbwaH2zQoByXRWon8buifX_PJyMe0Z15B4NYuJfdERIcGQaCyc16ASnyFeMA6G0YrBteUO40_rbCP59ZnuZQM2YxzTQDw9lSCWk4V4bauIsezs6APoCRr2GhR51N8A9zYo_EkT_Iz6F3T_2LteZZ0JwsqPVoy8cUnj2MM2uJRNJcJ6GLKPCGiSTX5-nUhu6V05HXuKNsYJSmBXdocH-Hfeyx-AhKhLWVIlcLtbbyWTr7t-8VmsjOJidhho2p0zqwOTQNqfPeTSOXi6oeqzkiMMTZqtWd13qUdZsB-SWI2cWNfwpnL3bDanGPkba5ivBzaHFH5g4sv-28mj8w0_Kav1Kigzt30AzlQxgnvo2bqHYwMsRQISs5iH7REGZUFgcFHFTwILhO6snY8JDjY9rsAeNuibCLyRsCJ30at-hRPJNR7JMfbPA&refId=QGoCTs2m3FDfMmPU5MDxsg%3D%3D&trackingId=y3S7UDlMKKBaEu8NuLtB%2BQ%3D%3D&trk=flagship3_search_srp_jobs)\n",
            "\n",
            "Job 5:\n",
            "  - Title: Software Solution Architect I\n",
            "  - Company: UST\n",
            "  - Location: Bengaluru, Karnataka, India\n",
            "  - Similarity Score: 0.79\n",
            "  - [Apply Here](https://www.linkedin.com/jobs/view/3975879524/?eBP=CwEAAAGTRaHGdev1gCx2jVO5z4PRiwLz2Y1ONCKzj1S6hiC_bB3DUi12YS7RiCLBwvc_KkxcHbiC2c26Jf9-lOA905KXDfdT4H09aQJZOpQq3YBBC0DBOBd7y_4ankJlcl9njIvF3hVZE_C8qCOULirJEAOf3iwNeudOVG3f82aG_rP8_e8bM9djAQRQbpAm3bzVivMCi-gY2g9V-SCfdDMwoTMarqLFIGEO_F5SFprxdEV_z1ASYoRT5ux4nOqQjPlNURc5qgii55UCJELqX__Doa3Jwn3k8w90p4Mp8lpHgB-8UII1QddqF9JbB8HhEeyPMS3DZz7SNvuEXWjlRdNvii6fuAZbMHyzqjxCDokcqxLmyO7Ao9fZwXma11FPsmqmOTB5Fj1p395x-_rB7FDMO8-gjvJpt1sUDyJg-5ASTenEKdJ3q6gBkiTGXor025bK1-dq8u3KjE86pZTAp_E07L6BGcegVMR3G2fyoYj7r1XBNwE9nAXkLtpnwPrkz0vf0HiDajas_oebbg&refId=3azH6MS4jVtUXR%2BP5fZ01w%3D%3D&trackingId=8%2BB%2F0M9bTFgH6ynDJeulRw%3D%3D&trk=flagship3_search_srp_jobs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Interface**"
      ],
      "metadata": {
        "id": "tBYqeEGr6Up0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "pS6ypw-b7GHp",
        "outputId": "fafe42e4-6de1-46f9-afc9-d24edf31bea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.6.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.3 (from gradio)\n",
            "  Downloading gradio_client-1.4.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.3->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.3->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.6.0-py3-none-any.whl (57.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.8.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.5 ffmpy-0.4.0 gradio-5.6.0 gradio-client-1.4.3 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.8.0 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.12.0 uvicorn-0.32.1 websockets-12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "markupsafe"
                ]
              },
              "id": "fb8b656bef6a43d6b8ad209f8b6ac2fd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import PyPDF2\n",
        "import gradio as gr\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Paths\n",
        "excel_path = \"/content/Student_Latest_Data/Student_Latest_Data/student_data.xlsx\"\n",
        "resume_folder = \"/content/Student_Latest_Data/Student_Latest_Data/New_resume\"\n",
        "job_csv_path = \"/content/new_jobs_jd_300.csv\"\n",
        "\n",
        "import os\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import PyPDF2\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import gradio as gr\n",
        "\n",
        "# Set up spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")  # Ensure the spaCy English model is downloaded\n",
        "\n",
        "# Load the job data\n",
        "job_data = pd.read_csv(job_csv_path)\n",
        "\n",
        "# Ensure required columns are present\n",
        "required_columns = ['Job Title', 'Company', 'Location', 'Link', 'Job_Description']\n",
        "if not all(col in job_data.columns for col in required_columns):\n",
        "    raise ValueError(\"Job data CSV file is missing required columns.\")\n",
        "\n",
        "# Function to preprocess text using spaCy (removes stop words and punctuation)\n",
        "def preprocess_text(text):\n",
        "    doc = nlp(text.lower())  # Process the text using spaCy\n",
        "    filtered_words = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "# Function to extract text from a PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "            return text\n",
        "    except Exception as e:\n",
        "        return f\"Error reading PDF: {e}\"\n",
        "\n",
        "# Function to recommend jobs\n",
        "def recommend_jobs(resume_text, job_data, top_n=5):\n",
        "    # Preprocess job descriptions\n",
        "    job_data['Processed_Job_Description'] = job_data['Job_Description'].fillna(\"\").apply(preprocess_text)\n",
        "\n",
        "    # Encode job descriptions and resume using Sentence-BERT\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    job_embeddings = model.encode(job_data['Processed_Job_Description'].tolist(), convert_to_tensor=True)\n",
        "    resume_embedding = model.encode(preprocess_text(resume_text), convert_to_tensor=True)\n",
        "\n",
        "    # Move tensors to CPU and convert to NumPy arrays\n",
        "    job_embeddings = job_embeddings.cpu().numpy()\n",
        "    resume_embedding = resume_embedding.cpu().numpy()\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    similarity_scores = cosine_similarity([resume_embedding], job_embeddings).flatten()\n",
        "    job_data['similarity_score'] = similarity_scores\n",
        "\n",
        "    # Get top job recommendations\n",
        "    top_jobs = job_data.nlargest(top_n, 'similarity_score')[['Job Title', 'Company', 'Location', 'Link', 'similarity_score']]\n",
        "    return top_jobs\n",
        "\n",
        "# Gradio function\n",
        "def job_recommender(roll_no):\n",
        "    resume_path = os.path.join(resume_folder, f\"{roll_no}.pdf\")\n",
        "\n",
        "    if not os.path.exists(resume_path):\n",
        "        return f\"Resume not found for Roll No: {roll_no}\"\n",
        "\n",
        "    # Extract text from the resume\n",
        "    resume_text = extract_text_from_pdf(resume_path)\n",
        "    if resume_text.startswith(\"Error\"):\n",
        "        return f\"Error reading resume for Roll No: {roll_no}\"\n",
        "\n",
        "    # Recommend jobs\n",
        "    top_jobs = recommend_jobs(resume_text, job_data)\n",
        "\n",
        "    # Prepare a response\n",
        "    results = []\n",
        "    for idx, job in enumerate(top_jobs.to_dict(orient='records'), start=1):\n",
        "        job_info = f\"**Job {idx}:**\\n\" \\\n",
        "                   f\"- **Title:** {job['Job Title']}\\n\" \\\n",
        "                   f\"- **Company:** {job['Company']}\\n\" \\\n",
        "                   f\"- **Location:** {job['Location']}\\n\" \\\n",
        "                   f\"- **Similarity Score:** {job['similarity_score']:.2f}\\n\" \\\n",
        "                   f\"- [Apply Here]({job['Link']})\"\n",
        "        results.append(job_info)\n",
        "\n",
        "    return \"\\n\\n\".join(results)\n",
        "\n",
        "# Set up Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=job_recommender,\n",
        "    inputs=gr.Textbox(label=\"Enter Roll Number\"),\n",
        "    outputs=gr.Markdown(label=\"Job Recommendations\"),\n",
        "    title=\"Job Recommendation System\",\n",
        "    description=\"Enter your roll number to get personalized job recommendations based on your resume.\"\n",
        ")\n",
        "\n",
        "# Launch the app\n",
        "if __name__ == \"__main__\":\n",
        "    iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "FeCsqv7d6WDA",
        "outputId": "2b701f2d-05aa-4bb6-8895-72c202a9b0ad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f402b45ca1a0cc6ec8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f402b45ca1a0cc6ec8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **InterFace 2**"
      ],
      "metadata": {
        "id": "CDdwQrs0PRZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import PyPDF2\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import gradio as gr\n",
        "\n",
        "# Set up spaCy\n",
        "nlp = spacy.load(\"en_core_web_sm\")  # Ensure the spaCy English model is downloaded\n",
        "\n",
        "# Paths\n",
        "excel_path = \"/content/Student_Latest_Data/Student_Latest_Data/student_data.xlsx\"\n",
        "resume_folder = \"/content/Student_Latest_Data/Student_Latest_Data/New_resume\"\n",
        "job_csv_path = \"/content/new_jobs_jd_300.csv\"\n",
        "\n",
        "\n",
        "# Load the student data (Roll Number and First Name)\n",
        "student_data = pd.read_excel(excel_path, usecols=[\"Roll No\", \"First Name\"])\n",
        "\n",
        "# Normalize the Roll Numbers (convert to string and strip spaces)\n",
        "student_data['Roll No'] = student_data['Roll No'].astype(str).str.strip()\n",
        "student_data.set_index(\"Roll No\", inplace=True)\n",
        "\n",
        "# Load the job data\n",
        "job_data = pd.read_csv(job_csv_path)\n",
        "\n",
        "# Ensure required columns are present\n",
        "required_columns = ['Job Title', 'Company', 'Location', 'Link', 'Job_Description']\n",
        "if not all(col in job_data.columns for col in required_columns):\n",
        "    raise ValueError(\"Job data CSV file is missing required columns.\")\n",
        "\n",
        "# Function to preprocess text using spaCy (removes stop words and punctuation)\n",
        "def preprocess_text(text):\n",
        "    doc = nlp(text.lower())  # Process the text using spaCy\n",
        "    filtered_words = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "# Function to extract text from a PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "            return text\n",
        "    except Exception as e:\n",
        "        return f\"Error reading PDF: {e}\"\n",
        "\n",
        "# Function to recommend jobs\n",
        "def recommend_jobs(resume_text, job_data, top_n=5):\n",
        "    # Preprocess job descriptions\n",
        "    job_data['Processed_Job_Description'] = job_data['Job_Description'].fillna(\"\").apply(preprocess_text)\n",
        "\n",
        "    # Encode job descriptions and resume using Sentence-BERT\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    job_embeddings = model.encode(job_data['Processed_Job_Description'].tolist(), convert_to_tensor=True)\n",
        "    resume_embedding = model.encode(preprocess_text(resume_text), convert_to_tensor=True)\n",
        "\n",
        "    # Move tensors to CPU and convert to NumPy arrays\n",
        "    job_embeddings = job_embeddings.cpu().numpy()\n",
        "    resume_embedding = resume_embedding.cpu().numpy()\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    similarity_scores = cosine_similarity([resume_embedding], job_embeddings).flatten()\n",
        "    job_data['similarity_score'] = similarity_scores\n",
        "\n",
        "    # Get top job recommendations\n",
        "    top_jobs = job_data.nlargest(top_n, 'similarity_score')[['Job Title', 'Company', 'Location', 'Link', 'similarity_score']]\n",
        "    return top_jobs\n",
        "\n",
        "# Gradio function\n",
        "def job_recommender(roll_no):\n",
        "    roll_no = str(roll_no).strip()  # Normalize input roll number\n",
        "    if roll_no not in student_data.index:\n",
        "        return f\"Roll Number {roll_no} not found in student data.\", \"\"\n",
        "\n",
        "    first_name = student_data.loc[roll_no, \"First Name\"]\n",
        "    resume_path = os.path.join(resume_folder, f\"{roll_no}.pdf\")\n",
        "\n",
        "    if not os.path.exists(resume_path):\n",
        "        return first_name, f\"Resume not found for Roll No: {roll_no} ({first_name})\"\n",
        "\n",
        "    # Extract text from the resume\n",
        "    resume_text = extract_text_from_pdf(resume_path)\n",
        "    if resume_text.startswith(\"Error\"):\n",
        "        return first_name, f\"Error reading resume for Roll No: {roll_no} ({first_name})\"\n",
        "\n",
        "    # Recommend jobs\n",
        "    top_jobs = recommend_jobs(resume_text, job_data)\n",
        "\n",
        "    # Prepare a response\n",
        "    recommendations = f\"**Top Job Recommendations for {first_name} (Roll No: {roll_no}):**\\n\\n\"\n",
        "    for idx, job in enumerate(top_jobs.to_dict(orient='records'), start=1):\n",
        "        job_info = f\"**Job {idx}:**\\n\" \\\n",
        "                   f\"- **Title:** {job['Job Title']}\\n\" \\\n",
        "                   f\"- **Company:** {job['Company']}\\n\" \\\n",
        "                   f\"- **Location:** {job['Location']}\\n\" \\\n",
        "                   f\"- **Similarity Score:** {job['similarity_score']:.2f}\\n\" \\\n",
        "                   f\"- [Apply Here]({job['Link']})\"\n",
        "        recommendations += job_info + \"\\n\\n\"\n",
        "\n",
        "    return first_name, recommendations\n",
        "\n",
        "# Set up Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=job_recommender,\n",
        "    inputs=gr.Textbox(label=\"Enter Roll Number\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"First Name\"),\n",
        "        gr.Markdown(label=\"Job Recommendations\")\n",
        "    ],\n",
        "    title=\"Job Recommendation System\",\n",
        "    description=\"Enter your roll number to get your name and personalized job recommendations based on your resume.\"\n",
        ")\n",
        "\n",
        "# Launch the app\n",
        "if __name__ == \"__main__\":\n",
        "    iface.launch()\n"
      ],
      "metadata": {
        "id": "zL367m0Q6Wr4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "1197e924-c959-4835-ec85-722fa086d24f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://dfd7fff9a60c5a07ef.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://dfd7fff9a60c5a07ef.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iZKis0aAEnCx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}